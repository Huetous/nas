{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'data' from 'C:\\\\Users\\\\daddu\\\\Desktop\\\\css\\\\practice_1\\\\data.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.models.mobilenet import build_mobilenet\n",
    "from enot.optimize import EnotPretrainOptimizer\n",
    "from enot.optimize import EnotSearchOptimizer\n",
    "\n",
    "from enot_utils.metric_utils import accuracy\n",
    "from enot_utils.schedulers import WarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path().absolute()\n",
    "ENOT_HOME_DIR = PATH / \"enot\"\n",
    "ENOT_DATASETS_DIR = PATH / \"datasets\"\n",
    "PROJECT_DIR = PATH / \"search\"\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets:\n",
    "1. train\n",
    "2. validation\n",
    "3. search\n",
    "4. test\n",
    "5. tune\n",
    "\n",
    "loaders:\n",
    "1. pretrain: train, val\n",
    "2. seach: train, val\n",
    "3. tune: train, val (same as pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = data.get_loaders(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrain': {'train': None, 'val': None},\n",
       " 'search': {'train': None, 'val': None},\n",
       " 'tune': {'train': None, 'val': None}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_OPS = [\n",
    "    \"MIB_k=3_t=6\",\n",
    "    \"MIB_k=5_t=6\",\n",
    "    \"MIB_k=7_t=6\",\n",
    "]\n",
    "\n",
    "model = build_mobilenet(\n",
    "    search_ops = SEARCH_OPS,\n",
    "    num_classes = 10,\n",
    "    blocks_out_channels= [24, 32, 64, 96, 160, 320],\n",
    "    blocks_count = [2, 2, 2, 1, 2, 1],\n",
    "    blocks_stride = [2, 2, 2, 1, 2, 1],\n",
    ")\n",
    "\n",
    "search_space = SearchSpaceModel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(search_space, \n",
    "          train_loader, valid_loader, \n",
    "          optimizer, enot_optimizer, \n",
    "          n_epochs, n_warmup_epochs, phase=\"pretrain\",\n",
    "          latency_loss_weight = 0):\n",
    "    \n",
    "    len_train_loader = len(train_loader)\n",
    "    scheduler = None\n",
    "    if phase != \"tune\":\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max = len_train_loader * n_epochs, eta_min = 1e-8)\n",
    "    if n_warmup_epochs > 0:\n",
    "        scheduler = WarmupScheduler(scheduler, warmup_steps = len_train_loader * n_warmup_epochs)\n",
    "\n",
    "    metric_function = accuracy\n",
    "    loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f\"Epoch #{epoch}\")\n",
    "\n",
    "        search_space.train()\n",
    "        train_metrics = {\n",
    "            \"loss\": 0.0,\n",
    "            \"accuracy\": 0.0,\n",
    "            \"n\": 0,\n",
    "        }\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            if phase == \"pretrain\":\n",
    "                if not search_space.initialize_output_distribution_enabled:\n",
    "                    search_space.initialize_output_distribution_optimization(inputs)\n",
    "            if phase == \"tune\":\n",
    "                optimizer.zero_grad()\n",
    "            else:\n",
    "                enot_optimizer.zero_grad()\n",
    "\n",
    "            def closure():\n",
    "                pred = search_space(inputs)\n",
    "                loss = loss_function(pred, labels)\n",
    "                \n",
    "                if phase == \"search\" and latency_loss_weight > 0:\n",
    "                    loss += search_space.loss_latency_expectation * latency_loss_weight\n",
    "                    \n",
    "                loss.backward()\n",
    "                metric = metric_function(pred, labels)\n",
    "\n",
    "                train_metrics[\"loss\"] += loss.item()\n",
    "                train_metrics[\"accuracy\"] += metric.item()\n",
    "                train_metrics[\"n\"] += 1\n",
    "            \n",
    "            if phase == \"tune\":\n",
    "                closure()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                enot_optimizer.step(closure)\n",
    "            \n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "        train_loss = train_metrics[\"loss\"] / train_metrics[\"n\"]\n",
    "        train_accuracy = train_metrics[\"accuracy\"] / train_metrics[\"n\"]\n",
    "        print(\"train metrics:\")\n",
    "        print(f\"\\tloss: {train_loss}\")\n",
    "        print(f\"\\taccuracy: {train_accuracy}\")\n",
    "        if phase == \"search\":\n",
    "            arch_probabilities = np.array(search_space.architecture_probabilities)\n",
    "            print(f\"\\tarch_probabilities: {arch_probabilities}\")\n",
    "\n",
    "        search_space.eval()\n",
    "        if phase == \"search\":\n",
    "            search_space.sample_best_arch()\n",
    "        \n",
    "        valid_loss = 0\n",
    "        valid_accuracy = 0\n",
    "        for inputs, labels in valid_loader:\n",
    "            if phase == \"pretrain\":\n",
    "                search_space.sample_random_arch()\n",
    "\n",
    "            pred = search_space(inputs)\n",
    "            loss = loss_function(pred, labels)\n",
    "            metric = metric_function(pred, labels)\n",
    "\n",
    "            validation_loss += batch_loss.item()\n",
    "            validation_accuracy += batch_metric.item()\n",
    "\n",
    "        n = len(validation_loader)\n",
    "        valid_loss /= n\n",
    "        valid_accuracy /= n\n",
    "\n",
    "        print(\"validation metrics:\")\n",
    "        print(f\"\\tloss: {valid_loss}\")\n",
    "        print(f\"\\taccuracy: {valid_accuracy}\")\n",
    "        if phase == \"search\" and search_space.latency_type is not None:\n",
    "            latency = search_space.forward_latency.item()\n",
    "            print(f\"\\tlatency: {latency}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "N_WARMUP_EPOCHS = 1\n",
    "LR = 6e-2\n",
    "\n",
    "train_loader = dataloaders[\"pretrain\"][\"train\"]\n",
    "valid_loader = dataloaders[\"pretrain\"][\"val\"]\n",
    "\n",
    "optimizer = SGD(params = search_space.model_parameters(), \n",
    "                lr=LR, momentum = 0.9, weight_decay = 1e-4)\n",
    "enot_optimizer = EnotPretrainOptimizer(search_space = search_space, optimizer = optimizer)\n",
    "\n",
    "train(search_space = search_space,\n",
    "      train_loader = train_loader,\n",
    "      valid_loader = valid_loader,\n",
    "      optimizer = optimizer,\n",
    "      enot_optimizer = enot_optimizer,\n",
    "      n_epochs = N_EPOCHS,\n",
    "      n_warmup_epochs = N_WARMUP_EPOCHS,\n",
    "      phase = \"pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "latency_loss_weight = 2e-3\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "enot_optimizer = EnotSearchOptimizer(search_space, optimizer, latency_type='mmac')\n",
    "\n",
    "train_loader = dataloaders['search'][\"train\"]\n",
    "valid_loader = dataloaders['search'][\"val\"]\n",
    "\n",
    "train(search_space = search_space,\n",
    "      train_loader = train_loader,\n",
    "      valid_loader = valid_loader,\n",
    "      optimizer = optimizer,\n",
    "      enot_optimizer = enot_optimizer,\n",
    "      n_epochs = N_EPOCHS,\n",
    "      phase = \"search\",\n",
    "      latency_loss_weight = latency_loss_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = search_space.get_network_with_best_arch().cuda()\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "optimizer = SGD(best_model.parameters(), lr=2e-4)\n",
    "\n",
    "train_loader = dataloaders['tune'][\"train\"]\n",
    "valid_loader = dataloaders['tune'][\"val\"]\n",
    "\n",
    "train(search_space = best_model,\n",
    "      train_loader = train_loader,\n",
    "      valid_loader = valid_loader,\n",
    "      optimizer = optimizer,\n",
    "      enot_optimizer = None,\n",
    "      n_epochs = N_EPOCHS,\n",
    "      n_warmup_epochs = 0,\n",
    "      phase = \"tune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
