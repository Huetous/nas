{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import deque\n",
    "from functools import singledispatch\n",
    "\n",
    "from typing import Any\n",
    "from typing import Dict\n",
    "from typing import Iterable\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "from typing import Tuple\n",
    "from typing import Set\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from enot.models.mobilenet import MobileNetBaseHead\n",
    "from enot.models.operations import SearchableMobileInvertedBottleneck\n",
    "from enot.models.operations import SearchVariantsContainer\n",
    "from torchvision.models.mobilenet import InvertedResidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TChannelsMapping = List[Tuple[int, int]]\n",
    "\n",
    "\n",
    "def conv2d_like(\n",
    "    src_conv: nn.Conv2d,\n",
    "    dst_in_channels: int,\n",
    "    dst_out_channels: int,\n",
    "    init_w_const: Optional[float] = 0.0,\n",
    ") -> nn.Conv2d:\n",
    "    groups = src_conv.groups\n",
    "    if src_conv.groups == src_conv.in_channels:\n",
    "        groups = dst_in_channels\n",
    "\n",
    "    bias = src_conv.bias is not None\n",
    "\n",
    "    dst_conv = nn.Conv2d(\n",
    "        in_channels=dst_in_channels, \n",
    "        out_channels=dst_out_channels, \n",
    "        kernel_size=src_conv.kernel_size, \n",
    "        stride=src_conv.stride, \n",
    "        padding=src_conv.padding, \n",
    "        dilation=src_conv.dilation, \n",
    "        groups=groups, \n",
    "        bias=bias, \n",
    "        padding_mode=src_conv.padding_mode,\n",
    "    )\n",
    "    if init_w_const is not None:\n",
    "        nn.init.constant_(dst_conv.weight, init_w_const)\n",
    "    \n",
    "    return dst_conv\n",
    "\n",
    "\n",
    "def bn_like(\n",
    "    src_bn: nn.BatchNorm2d,\n",
    "    dst_num_features: int,\n",
    ") -> nn.BatchNorm2d:\n",
    "    return nn.BatchNorm2d(\n",
    "        num_features=dst_num_features, \n",
    "        eps=src_bn.eps, \n",
    "        momentum=src_bn.momentum, \n",
    "        affine=src_bn.affine, \n",
    "        track_running_stats=src_bn.track_running_stats,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv2d_bn_like(\n",
    "    src_conv: nn.Conv2d,\n",
    "    src_bn: nn.Conv2d,\n",
    "    dst_in_channels: int,\n",
    "    dst_out_channels: int,\n",
    "    init_w_const: Optional[float] = None,\n",
    ") -> Tuple[nn.Conv2d, nn.BatchNorm2d]:\n",
    "    conv2d = conv2d_like(\n",
    "        src_conv,\n",
    "        dst_in_channels=dst_in_channels,\n",
    "        dst_out_channels=dst_out_channels,\n",
    "        init_w_const=init_w_const,\n",
    "    )\n",
    "    bn = bn_like(\n",
    "        src_bn=src_bn,\n",
    "        dst_num_features=dst_out_channels,\n",
    "    )\n",
    "\n",
    "    return conv2d, bn \n",
    "\n",
    "\n",
    "def get_mapping_from_bn(bn: nn.BatchNorm2d, dst_channels: int) -> TChannelsMapping:\n",
    "    if dst_channels <= 0:\n",
    "        raise ValueError('Number of destination channels must be > 0')\n",
    "\n",
    "    if not bn.track_running_stats:\n",
    "        raise ValueError('track_running_stats must be True')\n",
    "\n",
    "    src_channels = bn.num_features\n",
    "    if src_channels <= dst_channels:\n",
    "        return [(i, i) for i in range(src_channels)]\n",
    "    \n",
    "    score = bn.running_var.detach().cpu().numpy()\n",
    "    filtered_channels = np.argsort(-score)\n",
    "    filtered_channels = sorted(filtered_channels[:dst_channels])\n",
    "\n",
    "    return [\n",
    "        (src_ch, dst_ch)\n",
    "        for dst_ch, src_ch in enumerate(filtered_channels)\n",
    "    ]\n",
    "\n",
    "\n",
    "def _unpack_mapping(\n",
    "    mapping: Optional[TChannelsMapping],\n",
    ") -> Tuple[Tuple[int, ...], Tuple[int, ...]]:\n",
    "    src, dst = tuple(zip(*mapping))\n",
    "    if len(dst) != len(set(dst)):\n",
    "        raise RuntimeError('destination indexes must be unique')\n",
    "        \n",
    "    return list(src), list(dst)\n",
    "\n",
    "\n",
    "def _apply_mapping(\n",
    "    dst: torch.Tensor,\n",
    "    src: torch.Tensor,\n",
    "    mapping: Optional[TChannelsMapping],\n",
    ") -> None:\n",
    "    if mapping is None:\n",
    "        dst.copy_(src)\n",
    "        return\n",
    "    \n",
    "    src_indeces, dst_indeces = _unpack_mapping(mapping)\n",
    "    dst[dst_indeces] = src[src_indeces]\n",
    "\n",
    "    \n",
    "def _apply_mapping_out_in(\n",
    "    dst: torch.Tensor,\n",
    "    src: torch.Tensor,\n",
    "    out_mapping: Optional[TChannelsMapping],\n",
    "    in_mapping: Optional[TChannelsMapping],\n",
    ") -> None:\n",
    "    if in_mapping is None and out_mapping is None:\n",
    "        dst.copy_(src)\n",
    "        return\n",
    "\n",
    "    if out_mapping is not None:\n",
    "        src_out_indeces, dst_out_indeces = _unpack_mapping(out_mapping)\n",
    "    else:\n",
    "        src_out_indeces, dst_out_indeces = slice(None, None), slice(None, None)\n",
    "\n",
    "    if in_mapping is not None:\n",
    "        src_in_indeces, dst_in_indeces = _unpack_mapping(in_mapping)\n",
    "        if out_mapping is not None:\n",
    "            src_out_indeces = np.asarray(src_out_indeces)[:, np.newaxis]\n",
    "            dst_out_indeces = np.asarray(dst_out_indeces)[:, np.newaxis] \n",
    "    else:\n",
    "        src_in_indeces, dst_in_indeces = Ellipsis, Ellipsis\n",
    "    \n",
    "    dst[dst_out_indeces, dst_in_indeces] = src[src_out_indeces, src_in_indeces]\n",
    "\n",
    "\n",
    "def conv2d_apply_mapping(\n",
    "    dst_conv: nn.Conv2d, \n",
    "    src_conv: nn.Conv2d, \n",
    "    out_mapping: Optional[TChannelsMapping],\n",
    "    in_mapping: Optional[TChannelsMapping],\n",
    ") -> None:\n",
    "    if (src_conv.bias is None) != (dst_conv.bias is None):\n",
    "        raise ValueError('(src_conv.bias is None) != (dst_conv.bias is None)')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _apply_mapping_out_in(dst_conv.weight, src_conv.weight, out_mapping, in_mapping)\n",
    "\n",
    "        if dst_conv.bias is not None:\n",
    "            _apply_mapping(dst_conv.bias, src_conv.bias, out_mapping)\n",
    "\n",
    "            \n",
    "def bn_apply_mapping(\n",
    "    dst_bn: nn.BatchNorm2d, \n",
    "    src_bn: nn.BatchNorm2d, \n",
    "    mapping: Optional[TChannelsMapping],\n",
    ") -> None:\n",
    "    if src_bn.affine != dst_bn.affine:\n",
    "        raise ValueError('src_bn.affine != dst_bn.affine')\n",
    "    \n",
    "    if src_bn.track_running_stats != dst_bn.track_running_stats:\n",
    "        raise ValueError('src_bn.track_running_stats != dst_bn.track_running_stats')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if dst_bn.affine:\n",
    "            _apply_mapping(dst_bn.weight, src_bn.weight, mapping)\n",
    "            _apply_mapping(dst_bn.bias, src_bn.bias, mapping)\n",
    "\n",
    "        if dst_bn.track_running_stats:                \n",
    "            _apply_mapping(dst_bn.running_mean, src_bn.running_mean, mapping)\n",
    "            _apply_mapping(dst_bn.running_var, src_bn.running_var, mapping)\n",
    "            dst_bn.num_batches_tracked.copy_(src_bn.num_batches_tracked)\n",
    "            \n",
    "            \n",
    "def conv2d_bn_apply_mapping(\n",
    "    dst_conv: nn.Conv2d, \n",
    "    dst_bn: nn.BatchNorm2d, \n",
    "    src_conv: nn.Conv2d, \n",
    "    src_bn: nn.BatchNorm2d, \n",
    "    out_mapping: Optional[TChannelsMapping],\n",
    "    in_mapping: Optional[TChannelsMapping],\n",
    ") -> None:\n",
    "    conv2d_apply_mapping(\n",
    "        dst_conv=dst_conv, \n",
    "        src_conv=src_conv, \n",
    "        out_mapping=out_mapping,\n",
    "        in_mapping=in_mapping,\n",
    "    )\n",
    "    bn_apply_mapping(\n",
    "        dst_bn=dst_bn, \n",
    "        src_bn=src_bn, \n",
    "        mapping=out_mapping,\n",
    "    )\n",
    "    \n",
    "\n",
    "def create_conv2d_and_apply_mapping(\n",
    "    src_conv: nn.Conv2d,\n",
    "    dst_in_channels: int,\n",
    "    dst_out_channels: int,\n",
    "    out_mapping: Optional[TChannelsMapping],\n",
    "    in_mapping: Optional[TChannelsMapping],\n",
    ") -> nn.Conv2d:\n",
    "    dst_conv = conv2d_like(\n",
    "        src_conv=src_conv,\n",
    "        dst_in_channels=dst_in_channels,\n",
    "        dst_out_channels=dst_out_channels,\n",
    "        init_w_const=0.0,\n",
    "    )\n",
    "    conv2d_apply_mapping(\n",
    "        dst_conv=dst_conv, \n",
    "        src_conv=src_conv, \n",
    "        out_mapping=out_mapping,\n",
    "        in_mapping=in_mapping,\n",
    "    )\n",
    "\n",
    "    return dst_conv\n",
    "\n",
    "\n",
    "def create_bn_and_apply_mapping(\n",
    "    src_bn: nn.BatchNorm2d,\n",
    "    dst_num_features: int,\n",
    "    mapping: Optional[TChannelsMapping],\n",
    ") -> nn.BatchNorm2d:\n",
    "    dst_bn = bn_like(\n",
    "        src_bn=src_bn,\n",
    "        dst_num_features=dst_num_features,\n",
    "    )\n",
    "    bn_apply_mapping(\n",
    "        dst_bn=dst_bn, \n",
    "        src_bn=src_bn, \n",
    "        mapping=mapping,\n",
    "    )\n",
    "\n",
    "    return dst_bn\n",
    "\n",
    "\n",
    "def create_conv2d_bn_and_apply_mapping(\n",
    "    src_conv: nn.Conv2d,\n",
    "    src_bn: nn.BatchNorm2d,\n",
    "    dst_in_channels: int,\n",
    "    dst_out_channels: int,\n",
    "    out_mapping: Optional[TChannelsMapping],\n",
    "    in_mapping: Optional[TChannelsMapping],\n",
    ") -> Tuple[nn.Conv2d, nn.BatchNorm2d]:\n",
    "    dst_conv = create_conv2d_and_apply_mapping(\n",
    "        src_conv=src_conv,\n",
    "        dst_in_channels=dst_in_channels,\n",
    "        dst_out_channels=dst_out_channels,\n",
    "        out_mapping=out_mapping,\n",
    "        in_mapping=in_mapping,\n",
    "    )\n",
    "    dst_bn = create_bn_and_apply_mapping(\n",
    "        src_bn=src_bn,\n",
    "        dst_num_features=dst_out_channels,\n",
    "        mapping=out_mapping,\n",
    "    )\n",
    "    \n",
    "    return dst_conv, dst_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_MNv2_block_and_apply_mapping(\n",
    "    src_block: InvertedResidual, \n",
    "    dst_channels: int,\n",
    ") -> InvertedResidual:\n",
    "    if len(src_block.conv) != 4:\n",
    "        return None\n",
    "    \n",
    "    if type(src_block) is not InvertedResidual:\n",
    "        warnings.warn(\n",
    "            'Got subclass of InvertedResidual. Original InvertedResidual class '\n",
    "            'should be used to be ensure of correct generation of search variants. '\n",
    "            'In most of cases using subclass is ok.',\n",
    "            RuntimeWarning,\n",
    "        )\n",
    "\n",
    "    \n",
    "    bn_after_dws = src_block.conv[1][1]\n",
    "    mapping = get_mapping_from_bn(bn_after_dws, dst_channels)\n",
    "\n",
    "    dst_block = SearchableMobileInvertedBottleneck(\n",
    "        in_channels=src_block.conv[0][0].in_channels,\n",
    "        out_channels=src_block.conv[2].out_channels,\n",
    "        dw_channels=dst_channels,\n",
    "        kernel_size=3,\n",
    "        affine=True,\n",
    "        track=True,\n",
    "        activation='relu6',\n",
    "        use_skip_connection=src_block.use_res_connect,\n",
    "        \n",
    "        stride =   src_block.stride,\n",
    "        padding =  src_block.padding,\n",
    "        dilation = src_block.dilation\n",
    "    )\n",
    "    \n",
    "    # expand\n",
    "    src_expand = src_block.conv[0][0]\n",
    "    src_expand_bn = src_block.conv[0][1]\n",
    "    \n",
    "    dst_expand, dst_expand_bn = create_conv2d_bn_and_apply_mapping(\n",
    "        src_conv=src_expand,\n",
    "        src_bn=src_expand_bn,\n",
    "        dst_in_channels=src_expand.in_channels,\n",
    "        dst_out_channels=dst_channels,\n",
    "        out_mapping=mapping,\n",
    "        in_mapping=None,\n",
    "    )\n",
    "    \n",
    "    dst_block.expand_op[0].conv = dst_expand\n",
    "    dst_block.expand_op[0].bn = dst_expand_bn\n",
    "\n",
    "    # dws\n",
    "    src_dws = src_block.conv[1][0]\n",
    "    src_dws_bn = src_block.conv[1][1]\n",
    "    \n",
    "    dst_dws, dst_dws_bn = create_conv2d_bn_and_apply_mapping(\n",
    "        src_conv=src_dws,\n",
    "        src_bn=src_dws_bn,\n",
    "        dst_in_channels=dst_channels,\n",
    "        dst_out_channels=dst_channels,\n",
    "        out_mapping=mapping,\n",
    "        in_mapping=None,\n",
    "    )\n",
    "        \n",
    "    dst_block.depthwise_op[0].conv = dst_dws\n",
    "    dst_block.depthwise_op[0].bn = dst_dws_bn\n",
    "    \n",
    "    # project conv\n",
    "    src_project = src_block.conv[2]\n",
    "    src_project_bn = src_block.conv[3]\n",
    "\n",
    "    dst_project, dst_project_bn = create_conv2d_bn_and_apply_mapping(\n",
    "        src_conv=src_project,\n",
    "        src_bn=src_project_bn,\n",
    "        dst_in_channels=dst_channels,\n",
    "        dst_out_channels=src_project.out_channels,\n",
    "        out_mapping=None,\n",
    "        in_mapping=mapping,\n",
    "    )\n",
    "\n",
    "    dst_block.squeeze_op.conv = dst_project\n",
    "    dst_block.squeeze_op.bn = dst_project_bn\n",
    "\n",
    "    return dst_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@singledispatch\n",
    "def split_module_to_search_variants(src_module, **options) -> Optional[SearchVariantsContainer]:\n",
    "    return None\n",
    "\n",
    "\n",
    "@split_module_to_search_variants.register\n",
    "def _(src_module: InvertedResidual, **options) -> Optional[SearchVariantsContainer]:\n",
    "    if len(src_module.conv) != 4:\n",
    "        return None\n",
    "    \n",
    "    width_fractions = options.pop('width_fractions', [0.25, 0.5, 0.75, 1.0])\n",
    "    \n",
    "    bn_after_dws = src_module.conv[1][1]\n",
    "    src_channels = bn_after_dws.num_features\n",
    "\n",
    "    search_variants = []\n",
    "    for fraction in width_fractions:\n",
    "        if fraction == 1.0:\n",
    "            search_variants.append(deepcopy(src_module))\n",
    "        else:\n",
    "            dst_channels = max(int(src_channels*fraction), 1)\n",
    "            dst_module = create_MNv2_block_and_apply_mapping(src_module, dst_channels=dst_channels)\n",
    "            search_variants.append(dst_module)\n",
    "\n",
    "    return SearchVariantsContainer(search_variants)\n",
    "\n",
    "\n",
    "def build_model_with_search_variants(\n",
    "    model: nn.Module, \n",
    "    split_options_by_types: Optional[Dict[type, Dict[str, Any]]] = None,\n",
    "    split_options_by_modules: Optional[Dict[nn.Module, Dict[str, Any]]] = None,\n",
    "    excluded_types: Optional[Set[type]] = None, \n",
    "    excluded_modules: Optional[Set[nn.Module]] = None, \n",
    ") -> nn.Module:\n",
    "    if split_options_by_types is None:\n",
    "        split_options_by_types = dict()\n",
    "\n",
    "    if split_options_by_modules is None:\n",
    "        split_options_by_modules = dict()\n",
    "\n",
    "    if excluded_types is None:\n",
    "        excluded_types = set()\n",
    "\n",
    "    if excluded_modules is None:\n",
    "        excluded_modules = set()\n",
    "\n",
    "    def apply_split_module_to_search_variants(module):\n",
    "        if type(module) in excluded_types:\n",
    "            return None\n",
    "\n",
    "        if type(module) in excluded_modules:\n",
    "            return None\n",
    "            \n",
    "        options = split_options_by_modules.get(type(module), {})\n",
    "        if not options: \n",
    "            options = split_options_by_types.get(type(module), {})\n",
    "        \n",
    "        return split_module_to_search_variants(module, **options)\n",
    "    \n",
    "    result_model = apply_split_module_to_search_variants(model)\n",
    "    if result_model is not None:\n",
    "        return result_model\n",
    "\n",
    "    result_model = deepcopy(model)\n",
    "\n",
    "    queue = deque(((n,), m) for n, m in result_model.named_children())\n",
    "    while queue:\n",
    "        current_attr_path, current_module = queue.pop()\n",
    "\n",
    "        search_variants_container = apply_split_module_to_search_variants(current_module)\n",
    "        if search_variants_container is None:\n",
    "            for submodule_name, submodule in current_module.named_children():\n",
    "                submodule_attr_path = current_attr_path + (submodule_name,)\n",
    "                queue.append(\n",
    "                    (submodule_attr_path, submodule)\n",
    "                )\n",
    "        else:\n",
    "            target_module = result_model\n",
    "            for attr in current_attr_path[:-1]:\n",
    "                target_module = getattr(target_module, attr)\n",
    "            \n",
    "            attr = current_attr_path[-1]\n",
    "            setattr(target_module, attr, search_variants_container)\n",
    "\n",
    "    return result_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/igor/.cache/torch/hub/pytorch_vision_v0.8.0\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.8.0', 'mobilenet_v2', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "model_with_search_variants = build_model_with_search_variants(model, split_options_by_types={InvertedResidual: {'width_fractions': [0.25, 0.5]}})\n",
    "model_with_search_variants.classifier[1] = nn.Linear(in_features=1280, out_features=10, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def params_amount(model):\n",
    "    return np.sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnv2 = MobileNetV2()\n",
    "load_state_mnv2_pretrained(mnv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PoseEstimationWithMobileNet(backbone = mnv2.model, after_backbone_channels = 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_search_variants = build_model_with_search_variants(net, \n",
    "                                                              split_options_by_types={\n",
    "                                                                  InvertedResidual: {'width_fractions': [1.0, 0.5, 1/6]}\n",
    "                                                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = SearchSpaceModel(model_with_search_variants)\n",
    "torch.save(search_space.state_dict(), \"search_space_init.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SearchableMobileNetV2()\n",
    "net = PoseEstimationWithMobileNet(backbone = mnv2.model, after_backbone_channels = 96)\n",
    "search_space = SearchSpaceModel(net)\n",
    "search_space.load_state_dict(torch.load(\"search_space_init.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# You may need to change this variable to match free GPU index\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.models.mobilenet import build_mobilenet\n",
    "from enot.optimize import EnotPretrainOptimizer\n",
    "from enot.optimize import EnotSearchOptimizer\n",
    "\n",
    "from enot_utils.metric_utils import accuracy\n",
    "from enot_utils.schedulers import WarmupScheduler\n",
    "\n",
    "from tutorial_utils.checkpoints import download_getting_started_pretrain_checkpoint\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENOT_HOME_DIR = Path.home() / '.enot'\n",
    "ENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = ENOT_HOME_DIR / 'pruning_test'\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_imagenette_dataloaders(\n",
    "    dataset_root_dir=ENOT_DATASETS_DIR,\n",
    "    project_dir=PROJECT_DIR,\n",
    "    input_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model_with_search_variants).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0\n",
      "train metrics:\n",
      "  loss: 1.698934056023334\n",
      "  accuracy: 40.584367605980404\n",
      "validation metrics:\n",
      "  loss: 1.6638118374732234\n",
      "  accuracy: 51.391129032258064\n",
      "\n",
      "EPOCH #1\n",
      "train metrics:\n",
      "  loss: 1.347713968094359\n",
      "  accuracy: 58.15307328244473\n",
      "validation metrics:\n",
      "  loss: 1.489925630390644\n",
      "  accuracy: 56.95564516129032\n",
      "\n",
      "EPOCH #2\n",
      "train metrics:\n",
      "  loss: 1.1685503467600395\n",
      "  accuracy: 63.125738760765564\n",
      "validation metrics:\n",
      "  loss: 1.4963290958154587\n",
      "  accuracy: 55.01008064516129\n",
      "\n",
      "EPOCH #3\n",
      "train metrics:\n",
      "  loss: 1.0874943785210873\n",
      "  accuracy: 65.07535459640178\n",
      "validation metrics:\n",
      "  loss: 1.3672184644327048\n",
      "  accuracy: 57.57056451612903\n",
      "\n",
      "EPOCH #4\n",
      "train metrics:\n",
      "  loss: 1.0874536850350969\n",
      "  accuracy: 64.60919028748857\n",
      "validation metrics:\n",
      "  loss: 1.4683305130850883\n",
      "  accuracy: 58.346774193548384\n",
      "\n",
      "EPOCH #5\n",
      "train metrics:\n",
      "  loss: 1.0630275870891328\n",
      "  accuracy: 65.69666075199208\n",
      "validation metrics:\n",
      "  loss: 1.1600293024413046\n",
      "  accuracy: 65.45362903225806\n",
      "\n",
      "EPOCH #6\n",
      "train metrics:\n",
      "  loss: 1.0706308664159572\n",
      "  accuracy: 65.47650708137675\n",
      "validation metrics:\n",
      "  loss: 1.5800276456340667\n",
      "  accuracy: 49.375\n",
      "\n",
      "EPOCH #7\n",
      "train metrics:\n",
      "  loss: 1.0662108319870969\n",
      "  accuracy: 65.22680258243642\n",
      "validation metrics:\n",
      "  loss: 1.0612367735274377\n",
      "  accuracy: 64.54637096774194\n",
      "\n",
      "EPOCH #8\n",
      "train metrics:\n",
      "  loss: 1.051366500397946\n",
      "  accuracy: 65.44695626116814\n",
      "validation metrics:\n",
      "  loss: 1.0503086676040003\n",
      "  accuracy: 68.04435483870968\n",
      "\n",
      "EPOCH #9\n",
      "train metrics:\n",
      "  loss: 1.0489079595880306\n",
      "  accuracy: 66.15248224785988\n",
      "validation metrics:\n",
      "  loss: 1.212485454495876\n",
      "  accuracy: 64.32459677419355\n",
      "\n",
      "EPOCH #10\n",
      "train metrics:\n",
      "  loss: 1.0354365339938632\n",
      "  accuracy: 66.99615837259495\n",
      "validation metrics:\n",
      "  loss: 1.0202536442347112\n",
      "  accuracy: 66.67338709677419\n",
      "\n",
      "EPOCH #11\n",
      "train metrics:\n",
      "  loss: 1.0128894273270952\n",
      "  accuracy: 67.60268911808095\n",
      "validation metrics:\n",
      "  loss: 0.9960445881851258\n",
      "  accuracy: 68.1350806451613\n",
      "\n",
      "EPOCH #12\n",
      "train metrics:\n",
      "  loss: 0.936287308753805\n",
      "  accuracy: 69.54491724866502\n",
      "validation metrics:\n",
      "  loss: 1.0505408060646826\n",
      "  accuracy: 67.66129032258064\n",
      "\n",
      "EPOCH #13\n",
      "train metrics:\n",
      "  loss: 0.9130397401591565\n",
      "  accuracy: 70.32062646581771\n",
      "validation metrics:\n",
      "  loss: 0.761087525876299\n",
      "  accuracy: 76.04838709677419\n",
      "\n",
      "EPOCH #14\n",
      "train metrics:\n",
      "  loss: 0.8838501114160456\n",
      "  accuracy: 71.3489952574385\n",
      "validation metrics:\n",
      "  loss: 1.1129000065698018\n",
      "  accuracy: 66.09879032258064\n",
      "\n",
      "EPOCH #15\n",
      "train metrics:\n",
      "  loss: 0.870196090289887\n",
      "  accuracy: 72.02644797791827\n",
      "validation metrics:\n",
      "  loss: 0.8063736094101783\n",
      "  accuracy: 74.09274193548387\n",
      "\n",
      "EPOCH #16\n",
      "train metrics:\n",
      "  loss: 0.8314722377569117\n",
      "  accuracy: 73.14199171675013\n",
      "validation metrics:\n",
      "  loss: 0.9689148663873633\n",
      "  accuracy: 69.65725806451613\n",
      "\n",
      "EPOCH #17\n",
      "train metrics:\n",
      "  loss: 0.8241289720256277\n",
      "  accuracy: 73.53723402632043\n",
      "validation metrics:\n",
      "  loss: 0.7389367759948776\n",
      "  accuracy: 76.2600806451613\n",
      "\n",
      "EPOCH #18\n",
      "train metrics:\n",
      "  loss: 0.8120423544911628\n",
      "  accuracy: 73.81279548482692\n",
      "validation metrics:\n",
      "  loss: 0.7316754016905062\n",
      "  accuracy: 77.25806451612904\n",
      "\n",
      "EPOCH #19\n",
      "train metrics:\n",
      "  loss: 0.8158872162408017\n",
      "  accuracy: 73.94725176222781\n",
      "validation metrics:\n",
      "  loss: 0.676831154693519\n",
      "  accuracy: 78.92137096774194\n",
      "\n",
      "EPOCH #20\n",
      "train metrics:\n",
      "  loss: 0.7606315524337139\n",
      "  accuracy: 75.37086285530253\n",
      "validation metrics:\n",
      "  loss: 0.7187960450687716\n",
      "  accuracy: 77.30846774193549\n",
      "\n",
      "EPOCH #21\n",
      "train metrics:\n",
      "  loss: 0.7556911071564288\n",
      "  accuracy: 75.20020683775557\n",
      "validation metrics:\n",
      "  loss: 0.9814770495999725\n",
      "  accuracy: 69.73790322580645\n",
      "\n",
      "EPOCH #22\n",
      "train metrics:\n",
      "  loss: 0.758550139564149\n",
      "  accuracy: 75.44991133669589\n",
      "validation metrics:\n",
      "  loss: 0.7014706099946653\n",
      "  accuracy: 76.85483870967742\n",
      "\n",
      "EPOCH #23\n",
      "train metrics:\n",
      "  loss: 0.7450326236004525\n",
      "  accuracy: 76.19680849440554\n",
      "validation metrics:\n",
      "  loss: 0.6790956780314445\n",
      "  accuracy: 77.67137096774194\n",
      "\n",
      "EPOCH #24\n",
      "train metrics:\n",
      "  loss: 0.7257884983686691\n",
      "  accuracy: 76.51965127498545\n",
      "validation metrics:\n",
      "  loss: 0.7422349483165289\n",
      "  accuracy: 76.70362903225806\n",
      "\n",
      "EPOCH #25\n",
      "train metrics:\n",
      "  loss: 0.7308084457478625\n",
      "  accuracy: 76.66888296249066\n",
      "validation metrics:\n",
      "  loss: 0.563737407446869\n",
      "  accuracy: 82.20766129032258\n",
      "\n",
      "EPOCH #26\n",
      "train metrics:\n",
      "  loss: 0.6980129367493568\n",
      "  accuracy: 77.61524820530668\n",
      "validation metrics:\n",
      "  loss: 0.6770811155438423\n",
      "  accuracy: 77.87298387096774\n",
      "\n",
      "EPOCH #27\n",
      "train metrics:\n",
      "  loss: 0.7235043124949678\n",
      "  accuracy: 76.8291961994577\n",
      "validation metrics:\n",
      "  loss: 0.6576248752253671\n",
      "  accuracy: 78.55846774193549\n",
      "\n",
      "EPOCH #28\n",
      "train metrics:\n",
      "  loss: 0.6759851671913837\n",
      "  accuracy: 78.1471630989237\n",
      "validation metrics:\n",
      "  loss: 0.7158991159690965\n",
      "  accuracy: 77.77217741935483\n",
      "\n",
      "EPOCH #29\n",
      "train metrics:\n",
      "  loss: 0.6799763738474948\n",
      "  accuracy: 78.20404844892786\n",
      "validation metrics:\n",
      "  loss: 0.6327656821137474\n",
      "  accuracy: 79.73790322580645\n",
      "\n",
      "EPOCH #30\n",
      "train metrics:\n",
      "  loss: 0.6743295686993193\n",
      "  accuracy: 78.15824466461831\n",
      "validation metrics:\n",
      "  loss: 0.5773672393012431\n",
      "  accuracy: 82.25806451612904\n",
      "\n",
      "EPOCH #31\n",
      "train metrics:\n",
      "  loss: 0.6824686452429345\n",
      "  accuracy: 78.50325057658743\n",
      "validation metrics:\n",
      "  loss: 0.5464971152044111\n",
      "  accuracy: 82.05645161290323\n",
      "\n",
      "EPOCH #32\n",
      "train metrics:\n",
      "  loss: 0.6565612595449103\n",
      "  accuracy: 79.25014775052983\n",
      "validation metrics:\n",
      "  loss: 0.6123598266032434\n",
      "  accuracy: 81.54233870967742\n",
      "\n",
      "EPOCH #33\n",
      "train metrics:\n",
      "  loss: 0.6618488529895215\n",
      "  accuracy: 78.83052599480811\n",
      "validation metrics:\n",
      "  loss: 0.5708915639909045\n",
      "  accuracy: 82.45967741935483\n",
      "\n",
      "EPOCH #34\n",
      "train metrics:\n",
      "  loss: 0.6433053001444391\n",
      "  accuracy: 79.63874112392993\n",
      "validation metrics:\n",
      "  loss: 0.5786195289824279\n",
      "  accuracy: 82.1975806451613\n",
      "\n",
      "EPOCH #35\n",
      "train metrics:\n",
      "  loss: 0.6393643360822758\n",
      "  accuracy: 79.6032801202003\n",
      "validation metrics:\n",
      "  loss: 0.5553532801568508\n",
      "  accuracy: 81.44153225806451\n",
      "\n",
      "EPOCH #36\n",
      "train metrics:\n",
      "  loss: 0.6261510631505479\n",
      "  accuracy: 79.70079785610767\n",
      "validation metrics:\n",
      "  loss: 0.562384489443033\n",
      "  accuracy: 82.09677419354838\n",
      "\n",
      "EPOCH #37\n",
      "train metrics:\n",
      "  loss: 0.6084835588932037\n",
      "  accuracy: 80.15588060744265\n",
      "validation metrics:\n",
      "  loss: 0.5377609805474358\n",
      "  accuracy: 82.65120967741936\n",
      "\n",
      "EPOCH #38\n",
      "train metrics:\n",
      "  loss: 0.6228218792600835\n",
      "  accuracy: 79.88031913270342\n",
      "validation metrics:\n",
      "  loss: 0.5235989756521678\n",
      "  accuracy: 82.5100806451613\n",
      "\n",
      "EPOCH #39\n",
      "train metrics:\n",
      "  loss: 0.6018757054780391\n",
      "  accuracy: 80.34057328244474\n",
      "validation metrics:\n",
      "  loss: 0.5559939973041295\n",
      "  accuracy: 81.74395161290323\n",
      "\n",
      "EPOCH #40\n",
      "train metrics:\n",
      "  loss: 0.5980676152604691\n",
      "  accuracy: 80.63755908722572\n",
      "validation metrics:\n",
      "  loss: 0.48333973614799397\n",
      "  accuracy: 84.97983870967742\n",
      "\n",
      "EPOCH #41\n",
      "train metrics:\n",
      "  loss: 0.5895637722408518\n",
      "  accuracy: 81.11554372259911\n",
      "validation metrics:\n",
      "  loss: 0.5342740744592682\n",
      "  accuracy: 83.36693548387096\n",
      "\n",
      "EPOCH #42\n",
      "train metrics:\n",
      "  loss: 0.5844344953273205\n",
      "  accuracy: 81.42361109307471\n",
      "validation metrics:\n",
      "  loss: 0.5175635574776078\n",
      "  accuracy: 83.21572580645162\n",
      "\n",
      "EPOCH #43\n",
      "train metrics:\n",
      "  loss: 0.5805554278036381\n",
      "  accuracy: 81.04092787073013\n",
      "validation metrics:\n",
      "  loss: 0.5133008687426487\n",
      "  accuracy: 84.17338709677419\n",
      "\n",
      "EPOCH #44\n",
      "train metrics:\n",
      "  loss: 0.5756328098951502\n",
      "  accuracy: 81.45390069839802\n",
      "validation metrics:\n",
      "  loss: 0.48774420031376425\n",
      "  accuracy: 84.77822580645162\n",
      "\n",
      "EPOCH #45\n",
      "train metrics:\n",
      "  loss: 0.5754173621693824\n",
      "  accuracy: 81.56767136594083\n",
      "validation metrics:\n",
      "  loss: 0.5131326725466117\n",
      "  accuracy: 83.36693548387096\n",
      "\n",
      "EPOCH #46\n",
      "train metrics:\n",
      "  loss: 0.5599469955931319\n",
      "  accuracy: 81.52777776515231\n",
      "validation metrics:\n",
      "  loss: 0.49590798126413455\n",
      "  accuracy: 84.42540322580645\n",
      "\n",
      "EPOCH #47\n",
      "train metrics:\n",
      "  loss: 0.544695265876486\n",
      "  accuracy: 82.30570328083444\n",
      "validation metrics:\n",
      "  loss: 0.47453464321311445\n",
      "  accuracy: 84.42540322580645\n",
      "\n",
      "EPOCH #48\n",
      "train metrics:\n",
      "  loss: 0.5469129325386057\n",
      "  accuracy: 82.74822693682731\n",
      "validation metrics:\n",
      "  loss: 0.5369282544500404\n",
      "  accuracy: 82.66129032258064\n",
      "\n",
      "EPOCH #49\n",
      "train metrics:\n",
      "  loss: 0.5355300762868942\n",
      "  accuracy: 82.44680849440554\n",
      "validation metrics:\n",
      "  loss: 0.5289117319419259\n",
      "  accuracy: 82.61088709677419\n",
      "\n",
      "EPOCH #50\n",
      "train metrics:\n",
      "  loss: 0.5326549747047272\n",
      "  accuracy: 82.54728130584067\n",
      "validation metrics:\n",
      "  loss: 0.44829504077713334\n",
      "  accuracy: 86.18951612903226\n",
      "\n",
      "EPOCH #51\n",
      "train metrics:\n",
      "  loss: 0.5379388894806517\n",
      "  accuracy: 82.44385340264503\n",
      "validation metrics:\n",
      "  loss: 0.4174716889317478\n",
      "  accuracy: 86.84475806451613\n",
      "\n",
      "EPOCH #52\n",
      "train metrics:\n",
      "  loss: 0.5082374220674343\n",
      "  accuracy: 83.59929075849817\n",
      "validation metrics:\n",
      "  loss: 0.43287132602305184\n",
      "  accuracy: 86.44153225806451\n",
      "\n",
      "EPOCH #53\n",
      "train metrics:\n",
      "  loss: 0.5074083284811771\n",
      "  accuracy: 83.57934394998753\n",
      "validation metrics:\n",
      "  loss: 0.46346439856795535\n",
      "  accuracy: 85.48387096774194\n",
      "\n",
      "EPOCH #54\n",
      "train metrics:\n",
      "  loss: 0.4918736582740824\n",
      "  accuracy: 84.24940896541514\n",
      "validation metrics:\n",
      "  loss: 0.3829835815835864\n",
      "  accuracy: 88.05443548387096\n",
      "\n",
      "EPOCH #55\n",
      "train metrics:\n",
      "  loss: 0.4868402746129543\n",
      "  accuracy: 84.3868203183438\n",
      "validation metrics:\n",
      "  loss: 0.4456689043811733\n",
      "  accuracy: 85.43346774193549\n",
      "\n",
      "EPOCH #56\n",
      "train metrics:\n",
      "  loss: 0.49012105569560477\n",
      "  accuracy: 84.07284276434716\n",
      "validation metrics:\n",
      "  loss: 0.43536197451213676\n",
      "  accuracy: 86.18951612903226\n",
      "\n",
      "EPOCH #57\n",
      "train metrics:\n",
      "  loss: 0.4830941113385748\n",
      "  accuracy: 84.17553189866086\n",
      "validation metrics:\n",
      "  loss: 0.463798142729267\n",
      "  accuracy: 85.43346774193549\n",
      "\n",
      "EPOCH #58\n",
      "train metrics:\n",
      "  loss: 0.4597733773132588\n",
      "  accuracy: 84.86628249148104\n",
      "validation metrics:\n",
      "  loss: 0.3939961705717348\n",
      "  accuracy: 87.75201612903226\n",
      "\n",
      "EPOCH #59\n",
      "train metrics:\n",
      "  loss: 0.47180769034522646\n",
      "  accuracy: 84.45330966381316\n",
      "validation metrics:\n",
      "  loss: 0.40848437309144964\n",
      "  accuracy: 86.89516129032258\n",
      "\n",
      "EPOCH #60\n",
      "train metrics:\n",
      "  loss: 0.455848607722115\n",
      "  accuracy: 85.1366725515812\n",
      "validation metrics:\n",
      "  loss: 0.42198357429175126\n",
      "  accuracy: 87.14717741935483\n",
      "\n",
      "EPOCH #61\n",
      "train metrics:\n",
      "  loss: 0.45362670865464716\n",
      "  accuracy: 84.91060872179396\n",
      "validation metrics:\n",
      "  loss: 0.39746387765532537\n",
      "  accuracy: 88.20564516129032\n",
      "\n",
      "EPOCH #62\n",
      "train metrics:\n",
      "  loss: 0.4389408660537385\n",
      "  accuracy: 85.48980495371717\n",
      "validation metrics:\n",
      "  loss: 0.39887190982699394\n",
      "  accuracy: 87.3991935483871\n",
      "\n",
      "EPOCH #63\n",
      "train metrics:\n",
      "  loss: 0.44117270419572263\n",
      "  accuracy: 85.71734632126828\n",
      "validation metrics:\n",
      "  loss: 0.44311092283216214\n",
      "  accuracy: 85.98790322580645\n",
      "\n",
      "EPOCH #64\n",
      "train metrics:\n",
      "  loss: 0.4398519729680203\n",
      "  accuracy: 85.45360519733835\n",
      "validation metrics:\n",
      "  loss: 0.4043827935332252\n",
      "  accuracy: 87.55040322580645\n",
      "\n",
      "EPOCH #65\n",
      "train metrics:\n",
      "  loss: 0.4084434205230246\n",
      "  accuracy: 86.62751179147274\n",
      "validation metrics:\n",
      "  loss: 0.3803442127161449\n",
      "  accuracy: 88.15524193548387\n",
      "\n",
      "EPOCH #66\n",
      "train metrics:\n",
      "  loss: 0.4167308884494482\n",
      "  accuracy: 86.52186759786403\n",
      "validation metrics:\n",
      "  loss: 0.37811984180382663\n",
      "  accuracy: 88.25604838709677\n",
      "\n",
      "EPOCH #67\n",
      "train metrics:\n",
      "  loss: 0.41035902796590584\n",
      "  accuracy: 86.37559100211935\n",
      "validation metrics:\n",
      "  loss: 0.3924292306971526\n",
      "  accuracy: 87.70161290322581\n",
      "\n",
      "EPOCH #68\n",
      "train metrics:\n",
      "  loss: 0.41447081201254055\n",
      "  accuracy: 86.41474583402594\n",
      "validation metrics:\n",
      "  loss: 0.37756493261023877\n",
      "  accuracy: 88.00403225806451\n",
      "\n",
      "EPOCH #69\n",
      "train metrics:\n",
      "  loss: 0.3942251207188089\n",
      "  accuracy: 87.04861109307471\n",
      "validation metrics:\n",
      "  loss: 0.361718182361895\n",
      "  accuracy: 88.25604838709677\n",
      "\n",
      "EPOCH #70\n",
      "train metrics:\n",
      "  loss: 0.3895033285774766\n",
      "  accuracy: 87.46749407179813\n",
      "validation metrics:\n",
      "  loss: 0.40922215682334234\n",
      "  accuracy: 87.75201612903226\n",
      "\n",
      "EPOCH #71\n",
      "train metrics:\n",
      "  loss: 0.3974528065387239\n",
      "  accuracy: 86.98212173137259\n",
      "validation metrics:\n",
      "  loss: 0.3588822290842091\n",
      "  accuracy: 88.35685483870968\n",
      "\n",
      "EPOCH #72\n",
      "train metrics:\n",
      "  loss: 0.3753564329540476\n",
      "  accuracy: 87.70685577392578\n",
      "validation metrics:\n",
      "  loss: 0.355323520736889\n",
      "  accuracy: 88.9616935483871\n",
      "\n",
      "EPOCH #73\n",
      "train metrics:\n",
      "  loss: 0.3759947615735074\n",
      "  accuracy: 87.81176121488531\n",
      "validation metrics:\n",
      "  loss: 0.33835596551427677\n",
      "  accuracy: 89.61693548387096\n",
      "\n",
      "EPOCH #74\n",
      "train metrics:\n",
      "  loss: 0.3804143655331845\n",
      "  accuracy: 87.35667847978308\n",
      "validation metrics:\n",
      "  loss: 0.33490357145426736\n",
      "  accuracy: 89.46572580645162\n",
      "\n",
      "EPOCH #75\n",
      "train metrics:\n",
      "  loss: 0.3711133029232634\n",
      "  accuracy: 87.77186759786403\n",
      "validation metrics:\n",
      "  loss: 0.3430900201351652\n",
      "  accuracy: 89.26411290322581\n",
      "\n",
      "EPOCH #76\n",
      "train metrics:\n",
      "  loss: 0.35807555099116994\n",
      "  accuracy: 88.63622929999168\n",
      "validation metrics:\n",
      "  loss: 0.3506968562160769\n",
      "  accuracy: 89.0625\n",
      "\n",
      "EPOCH #77\n",
      "train metrics:\n",
      "  loss: 0.37329687558590097\n",
      "  accuracy: 88.03930258243642\n",
      "validation metrics:\n",
      "  loss: 0.32131236512213945\n",
      "  accuracy: 90.12096774193549\n",
      "\n",
      "EPOCH #78\n",
      "train metrics:\n",
      "  loss: 0.35886972140758594\n",
      "  accuracy: 88.57860519733835\n",
      "validation metrics:\n",
      "  loss: 0.32419032627536404\n",
      "  accuracy: 89.01209677419355\n",
      "\n",
      "EPOCH #79\n",
      "train metrics:\n",
      "  loss: 0.3498471532571823\n",
      "  accuracy: 88.62884157870678\n",
      "validation metrics:\n",
      "  loss: 0.3330843750642793\n",
      "  accuracy: 89.31451612903226\n",
      "\n",
      "EPOCH #80\n",
      "train metrics:\n",
      "  loss: 0.34290024925895196\n",
      "  accuracy: 89.06176121488531\n",
      "validation metrics:\n",
      "  loss: 0.3320952147065151\n",
      "  accuracy: 89.71774193548387\n",
      "\n",
      "EPOCH #81\n",
      "train metrics:\n",
      "  loss: 0.337428635335032\n",
      "  accuracy: 89.07210401169797\n",
      "validation metrics:\n",
      "  loss: 0.3186336362193669\n",
      "  accuracy: 90.42338709677419\n",
      "\n",
      "EPOCH #82\n",
      "train metrics:\n",
      "  loss: 0.34087267373787594\n",
      "  accuracy: 89.06841015105552\n",
      "validation metrics:\n",
      "  loss: 0.34400671373511993\n",
      "  accuracy: 88.70967741935483\n",
      "\n",
      "EPOCH #83\n",
      "train metrics:\n",
      "  loss: 0.32917073941294184\n",
      "  accuracy: 89.12234040929916\n",
      "validation metrics:\n",
      "  loss: 0.3166090046776639\n",
      "  accuracy: 90.37298387096774\n",
      "\n",
      "EPOCH #84\n",
      "train metrics:\n",
      "  loss: 0.3268952564831744\n",
      "  accuracy: 89.47547279520238\n",
      "validation metrics:\n",
      "  loss: 0.35055609675304544\n",
      "  accuracy: 88.9616935483871\n",
      "\n",
      "EPOCH #85\n",
      "train metrics:\n",
      "  loss: 0.3290684606008073\n",
      "  accuracy: 89.4739952574385\n",
      "validation metrics:\n",
      "  loss: 0.3282203392666434\n",
      "  accuracy: 89.71774193548387\n",
      "\n",
      "EPOCH #86\n",
      "train metrics:\n",
      "  loss: 0.3274502971863493\n",
      "  accuracy: 89.49098699042138\n",
      "validation metrics:\n",
      "  loss: 0.3190297873225063\n",
      "  accuracy: 89.71774193548387\n",
      "\n",
      "EPOCH #87\n",
      "train metrics:\n",
      "  loss: 0.3108890027758923\n",
      "  accuracy: 90.27260638297872\n",
      "validation metrics:\n",
      "  loss: 0.3283704241902958\n",
      "  accuracy: 89.66733870967742\n",
      "\n",
      "EPOCH #88\n",
      "train metrics:\n",
      "  loss: 0.3052767747180893\n",
      "  accuracy: 90.12411346435547\n",
      "validation metrics:\n",
      "  loss: 0.2977868360767682\n",
      "  accuracy: 90.3225806451613\n",
      "\n",
      "EPOCH #89\n",
      "train metrics:\n",
      "  loss: 0.3346419431427692\n",
      "  accuracy: 89.30703306806848\n",
      "validation metrics:\n",
      "  loss: 0.3229546228183373\n",
      "  accuracy: 89.91935483870968\n",
      "\n",
      "EPOCH #90\n",
      "train metrics:\n",
      "  loss: 0.30017687650595576\n",
      "  accuracy: 90.55333923989154\n",
      "validation metrics:\n",
      "  loss: 0.315058074290714\n",
      "  accuracy: 89.81854838709677\n",
      "\n",
      "EPOCH #91\n",
      "train metrics:\n",
      "  loss: 0.31309252453849035\n",
      "  accuracy: 89.92242905637052\n",
      "validation metrics:\n",
      "  loss: 0.31501634842565945\n",
      "  accuracy: 90.42338709677419\n",
      "\n",
      "EPOCH #92\n",
      "train metrics:\n",
      "  loss: 0.31540806444877006\n",
      "  accuracy: 89.87293142765127\n",
      "validation metrics:\n",
      "  loss: 0.3056421973066585\n",
      "  accuracy: 90.57459677419355\n",
      "\n",
      "EPOCH #93\n",
      "train metrics:\n",
      "  loss: 0.3122005403517409\n",
      "  accuracy: 90.24896571382563\n",
      "validation metrics:\n",
      "  loss: 0.3231824967229078\n",
      "  accuracy: 90.17137096774194\n",
      "\n",
      "EPOCH #94\n",
      "train metrics:\n",
      "  loss: 0.30209651399166026\n",
      "  accuracy: 90.4343971414769\n",
      "validation metrics:\n",
      "  loss: 0.3187718087687127\n",
      "  accuracy: 90.22177419354838\n",
      "\n",
      "EPOCH #95\n",
      "train metrics:\n",
      "  loss: 0.3217705518403586\n",
      "  accuracy: 89.8167848627618\n",
      "validation metrics:\n",
      "  loss: 0.3124513675819241\n",
      "  accuracy: 90.47379032258064\n",
      "\n",
      "EPOCH #96\n",
      "train metrics:\n",
      "  loss: 0.30696423875683165\n",
      "  accuracy: 90.13223993828956\n",
      "validation metrics:\n",
      "  loss: 0.3081542913531584\n",
      "  accuracy: 90.3225806451613\n",
      "\n",
      "EPOCH #97\n",
      "train metrics:\n",
      "  loss: 0.3058344089842223\n",
      "  accuracy: 90.01994680851064\n",
      "validation metrics:\n",
      "  loss: 0.29758892666112874\n",
      "  accuracy: 90.3225806451613\n",
      "\n",
      "EPOCH #98\n",
      "train metrics:\n",
      "  loss: 0.2914810977678033\n",
      "  accuracy: 90.60726948190242\n",
      "validation metrics:\n",
      "  loss: 0.3261632923817923\n",
      "  accuracy: 89.71774193548387\n",
      "\n",
      "EPOCH #99\n",
      "train metrics:\n",
      "  loss: 0.29863091677506554\n",
      "  accuracy: 90.61391841807264\n",
      "validation metrics:\n",
      "  loss: 0.32048667211746495\n",
      "  accuracy: 89.96975806451613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "N_WARMUP_EPOCHS = 10\n",
    "\n",
    "train_loader = dataloaders['pretrain_train_dataloader']\n",
    "validation_loader = dataloaders['pretrain_validation_dataloader']\n",
    "\n",
    "# using `search_space.model_parameters()` as optimizable variables\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "# using `EnotPretrainOptimizer` as a default optimizer\n",
    "enot_optimizer = EnotPretrainOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "\n",
    "len_train_loader = len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train_loader*N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train_loader*N_WARMUP_EPOCHS)\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    search_space.train()\n",
    "    train_metrics_acc = {\n",
    "        'loss': 0.0,\n",
    "        'accuracy': 0.0,\n",
    "        'n': 0,\n",
    "    }\n",
    "    for inputs, labels in train_loader:\n",
    "        # By default, `EnotPretrainOptimizer` requires one batch of train data to initialize optimizations, \n",
    "        # so you should run `search_space.initialize_output_distribution_optimization(...)` before the first \n",
    "        # model step. You can disable optimization checking in `EnotPretrainOptimizer` constructor \n",
    "        # (`check_recommended_optimizations` parameter), but this is not recommended.\n",
    "        if not search_space.output_distribution_optimization_enabled:\n",
    "            search_space.initialize_output_distribution_optimization(inputs)\n",
    "\n",
    "        enot_optimizer.zero_grad()\n",
    "        # Wrapping model step and backward with closure.\n",
    "        # Alternatively, here is `enot_optimizer.model_step(...)` example usage for gradient accumulation:\n",
    "        #\n",
    "        # enot_optimizer.zero_grad()\n",
    "        # for inputs, labels in train_loader:\n",
    "        #\n",
    "        #     def closure():\n",
    "        #         ...\n",
    "        #\n",
    "        #     enot_optimizer.model_step(closure)\n",
    "        #     if (n + 1) % 10 == 0:\n",
    "        #         enot_optimizer.step()\n",
    "        #         enot_optimizer.zero_grad()\n",
    "        def closure():\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_loss.backward()\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            train_metrics_acc['loss'] += batch_loss.item()\n",
    "            train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "            train_metrics_acc['n'] += 1\n",
    "\n",
    "        enot_optimizer.step(closure)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "    train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "\n",
    "    search_space.eval()\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    for inputs, labels in validation_loader:\n",
    "\n",
    "        # Sample random architecture from the search space to estimate\n",
    "        # search space expected metrics.\n",
    "        search_space.sample_random_arch()\n",
    "\n",
    "        pred_labels = search_space(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "        validation_loss += batch_loss.item()\n",
    "        validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCH #99\n",
    "# train metrics:\n",
    "#   loss: 0.29863091677506554\n",
    "#   accuracy: 90.61391841807264\n",
    "# validation metrics:\n",
    "#   loss: 0.32048667211746495\n",
    "#   accuracy: 89.96975806451613\n",
    "\n",
    "# torch.save({'model': search_space.state_dict()}, PROJECT_DIR / 'prune_init_result.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in search_space.modules():\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0\n",
      "train metrics:\n",
      "  loss: 2.307060359893961\n",
      "  accuracy: 12.71128841562474\n",
      "validation metrics:\n",
      "  loss: 3.0902600749846427\n",
      "  accuracy: 8.921370967741936\n",
      "\n",
      "EPOCH #1\n",
      "train metrics:\n",
      "  loss: 2.30292133270426\n",
      "  accuracy: 17.18011229088966\n",
      "validation metrics:\n",
      "  loss: 2.825388700731339\n",
      "  accuracy: 19.758064516129032\n",
      "\n",
      "EPOCH #2\n",
      "train metrics:\n",
      "  loss: 2.298670430639957\n",
      "  accuracy: 20.09086879162078\n",
      "validation metrics:\n",
      "  loss: 2.7842245462440673\n",
      "  accuracy: 19.294354838709676\n",
      "\n",
      "EPOCH #3\n",
      "train metrics:\n",
      "  loss: 2.1483039579492935\n",
      "  accuracy: 25.425531910835428\n",
      "validation metrics:\n",
      "  loss: 2.1391234859343498\n",
      "  accuracy: 25.866935483870968\n",
      "\n",
      "EPOCH #4\n",
      "train metrics:\n",
      "  loss: 1.9964911884449899\n",
      "  accuracy: 29.701536633105988\n",
      "validation metrics:\n",
      "  loss: 1.9094789489623039\n",
      "  accuracy: 34.243951612903224\n",
      "\n",
      "EPOCH #5\n",
      "train metrics:\n",
      "  loss: 1.8526982287143139\n",
      "  accuracy: 36.02171984733419\n",
      "validation metrics:\n",
      "  loss: 1.8766882438813486\n",
      "  accuracy: 33.538306451612904\n",
      "\n",
      "EPOCH #6\n",
      "train metrics:\n",
      "  loss: 1.768604184972479\n",
      "  accuracy: 37.58126477180643\n",
      "validation metrics:\n",
      "  loss: 1.819563663774921\n",
      "  accuracy: 35.372983870967744\n",
      "\n",
      "EPOCH #7\n",
      "train metrics:\n",
      "  loss: 1.7175019520394346\n",
      "  accuracy: 39.742169027125584\n",
      "validation metrics:\n",
      "  loss: 1.818572308747999\n",
      "  accuracy: 41.40120967741935\n",
      "\n",
      "EPOCH #8\n",
      "train metrics:\n",
      "  loss: 1.636281313033814\n",
      "  accuracy: 43.0924940799145\n",
      "validation metrics:\n",
      "  loss: 1.631224040062197\n",
      "  accuracy: 45.28225806451613\n",
      "\n",
      "EPOCH #9\n",
      "train metrics:\n",
      "  loss: 1.5840430822778255\n",
      "  accuracy: 45.200945614753884\n",
      "validation metrics:\n",
      "  loss: 1.5054562293714093\n",
      "  accuracy: 47.22782258064516\n",
      "\n",
      "EPOCH #10\n",
      "train metrics:\n",
      "  loss: 1.5627243326065388\n",
      "  accuracy: 46.42656618483523\n",
      "validation metrics:\n",
      "  loss: 1.4701637260375484\n",
      "  accuracy: 50.020161290322584\n",
      "\n",
      "EPOCH #11\n",
      "train metrics:\n",
      "  loss: 1.5135461561223293\n",
      "  accuracy: 48.58673167127244\n",
      "validation metrics:\n",
      "  loss: 1.436286602289446\n",
      "  accuracy: 50.131048387096776\n",
      "\n",
      "EPOCH #12\n",
      "train metrics:\n",
      "  loss: 1.482856162050937\n",
      "  accuracy: 49.84707445996873\n",
      "validation metrics:\n",
      "  loss: 1.3773294802634948\n",
      "  accuracy: 52.51008064516129\n",
      "\n",
      "EPOCH #13\n",
      "train metrics:\n",
      "  loss: 1.4438409817979692\n",
      "  accuracy: 51.21527777326868\n",
      "validation metrics:\n",
      "  loss: 1.529383820872153\n",
      "  accuracy: 50.74596774193548\n",
      "\n",
      "EPOCH #14\n",
      "train metrics:\n",
      "  loss: 1.4116826578657677\n",
      "  accuracy: 52.12470448270757\n",
      "validation metrics:\n",
      "  loss: 1.4202178966614507\n",
      "  accuracy: 52.96370967741935\n",
      "\n",
      "EPOCH #15\n",
      "train metrics:\n",
      "  loss: 1.3519476307199356\n",
      "  accuracy: 54.859633555310836\n",
      "validation metrics:\n",
      "  loss: 1.2074358208525566\n",
      "  accuracy: 59.868951612903224\n",
      "\n",
      "EPOCH #16\n",
      "train metrics:\n",
      "  loss: 1.3236853688321215\n",
      "  accuracy: 56.12662528829372\n",
      "validation metrics:\n",
      "  loss: 1.3438988246263996\n",
      "  accuracy: 54.979838709677416\n",
      "\n",
      "EPOCH #17\n",
      "train metrics:\n",
      "  loss: 1.3063197148607133\n",
      "  accuracy: 56.78191488550065\n",
      "validation metrics:\n",
      "  loss: 1.3438501132111396\n",
      "  accuracy: 55.47379032258065\n",
      "\n",
      "EPOCH #18\n",
      "train metrics:\n",
      "  loss: 1.2832169847285493\n",
      "  accuracy: 57.71572103297457\n",
      "validation metrics:\n",
      "  loss: 1.4724329181255833\n",
      "  accuracy: 52.80241935483871\n",
      "\n",
      "EPOCH #19\n",
      "train metrics:\n",
      "  loss: 1.2539073497691053\n",
      "  accuracy: 58.4980791781811\n",
      "validation metrics:\n",
      "  loss: 1.3557555887006945\n",
      "  accuracy: 56.078629032258064\n",
      "\n",
      "EPOCH #20\n",
      "train metrics:\n",
      "  loss: 1.2225461484269893\n",
      "  accuracy: 59.40307328244473\n",
      "validation metrics:\n",
      "  loss: 1.197307541005073\n",
      "  accuracy: 60.877016129032256\n",
      "\n",
      "EPOCH #21\n",
      "train metrics:\n",
      "  loss: 1.205306214094162\n",
      "  accuracy: 60.135933798932015\n",
      "validation metrics:\n",
      "  loss: 1.2505270670498572\n",
      "  accuracy: 58.82056451612903\n",
      "\n",
      "EPOCH #22\n",
      "train metrics:\n",
      "  loss: 1.1850350239175431\n",
      "  accuracy: 61.12662528829372\n",
      "validation metrics:\n",
      "  loss: 1.158586441989868\n",
      "  accuracy: 61.17943548387097\n",
      "\n",
      "EPOCH #23\n",
      "train metrics:\n",
      "  loss: 1.1793701173143183\n",
      "  accuracy: 61.244089816478976\n",
      "validation metrics:\n",
      "  loss: 1.1741784404843085\n",
      "  accuracy: 61.17943548387097\n",
      "\n",
      "EPOCH #24\n",
      "train metrics:\n",
      "  loss: 1.1567823881798602\n",
      "  accuracy: 61.97916665584483\n",
      "validation metrics:\n",
      "  loss: 1.102932499301049\n",
      "  accuracy: 63.256048387096776\n",
      "\n",
      "EPOCH #25\n",
      "train metrics:\n",
      "  loss: 1.1100532865270656\n",
      "  accuracy: 63.576388874459774\n",
      "validation metrics:\n",
      "  loss: 1.0551861445269277\n",
      "  accuracy: 65.57459677419355\n",
      "\n",
      "EPOCH #26\n",
      "train metrics:\n",
      "  loss: 1.111279768132149\n",
      "  accuracy: 63.2771867468002\n",
      "validation metrics:\n",
      "  loss: 1.1464676712789843\n",
      "  accuracy: 60.877016129032256\n",
      "\n",
      "EPOCH #27\n",
      "train metrics:\n",
      "  loss: 1.0687552624560417\n",
      "  accuracy: 64.96601653403424\n",
      "validation metrics:\n",
      "  loss: 1.026840291917324\n",
      "  accuracy: 66.52217741935483\n",
      "\n",
      "EPOCH #28\n",
      "train metrics:\n",
      "  loss: 1.0722387401347464\n",
      "  accuracy: 65.0605791781811\n",
      "validation metrics:\n",
      "  loss: 1.056851835981492\n",
      "  accuracy: 65.20161290322581\n",
      "\n",
      "EPOCH #29\n",
      "train metrics:\n",
      "  loss: 1.0664695194427003\n",
      "  accuracy: 65.0842198473342\n",
      "validation metrics:\n",
      "  loss: 1.098572217468773\n",
      "  accuracy: 63.538306451612904\n",
      "\n",
      "EPOCH #30\n",
      "train metrics:\n",
      "  loss: 1.0487428514247246\n",
      "  accuracy: 66.03354018191074\n",
      "validation metrics:\n",
      "  loss: 1.2093702530668629\n",
      "  accuracy: 60.453629032258064\n",
      "\n",
      "EPOCH #31\n",
      "train metrics:\n",
      "  loss: 1.0351758640497288\n",
      "  accuracy: 66.26403664122236\n",
      "validation metrics:\n",
      "  loss: 0.9043106431922605\n",
      "  accuracy: 70.16129032258064\n",
      "\n",
      "EPOCH #32\n",
      "train metrics:\n",
      "  loss: 0.9952325458222248\n",
      "  accuracy: 67.34042553191489\n",
      "validation metrics:\n",
      "  loss: 0.9062768790510393\n",
      "  accuracy: 70.40322580645162\n",
      "\n",
      "EPOCH #33\n",
      "train metrics:\n",
      "  loss: 0.9925340865520721\n",
      "  accuracy: 67.53841607114101\n",
      "validation metrics:\n",
      "  loss: 0.903332487229378\n",
      "  accuracy: 70.54435483870968\n",
      "\n",
      "EPOCH #34\n",
      "train metrics:\n",
      "  loss: 0.9880038144740653\n",
      "  accuracy: 67.90263001462246\n",
      "validation metrics:\n",
      "  loss: 0.9874793101222284\n",
      "  accuracy: 67.68145161290323\n",
      "\n",
      "EPOCH #35\n",
      "train metrics:\n",
      "  loss: 0.9650671310247259\n",
      "  accuracy: 68.6960697255236\n",
      "validation metrics:\n",
      "  loss: 0.9116055842849516\n",
      "  accuracy: 69.14314516129032\n",
      "\n",
      "EPOCH #36\n",
      "train metrics:\n",
      "  loss: 0.9431107174842915\n",
      "  accuracy: 68.66356382978724\n",
      "validation metrics:\n",
      "  loss: 0.9374562257960919\n",
      "  accuracy: 70.0\n",
      "\n",
      "EPOCH #37\n",
      "train metrics:\n",
      "  loss: 0.942220172412852\n",
      "  accuracy: 69.55378249148104\n",
      "validation metrics:\n",
      "  loss: 0.8304107478789745\n",
      "  accuracy: 71.61290322580645\n",
      "\n",
      "EPOCH #38\n",
      "train metrics:\n",
      "  loss: 0.9390213123027314\n",
      "  accuracy: 69.23241724866502\n",
      "validation metrics:\n",
      "  loss: 0.899257977342894\n",
      "  accuracy: 69.90927419354838\n",
      "\n",
      "EPOCH #39\n",
      "train metrics:\n",
      "  loss: 0.9102111733340202\n",
      "  accuracy: 69.99926122300168\n",
      "validation metrics:\n",
      "  loss: 0.8127533364440164\n",
      "  accuracy: 73.17540322580645\n",
      "\n",
      "EPOCH #40\n",
      "train metrics:\n",
      "  loss: 0.8976509281929503\n",
      "  accuracy: 70.38416072764295\n",
      "validation metrics:\n",
      "  loss: 0.8264729580090892\n",
      "  accuracy: 72.32862903225806\n",
      "\n",
      "EPOCH #41\n",
      "train metrics:\n",
      "  loss: 0.9075320083410182\n",
      "  accuracy: 70.46247042392163\n",
      "validation metrics:\n",
      "  loss: 0.8385044665586564\n",
      "  accuracy: 71.65322580645162\n",
      "\n",
      "EPOCH #42\n",
      "train metrics:\n",
      "  loss: 0.8683227286693898\n",
      "  accuracy: 71.23300826701713\n",
      "validation metrics:\n",
      "  loss: 0.8666063789879123\n",
      "  accuracy: 72.32862903225806\n",
      "\n",
      "EPOCH #43\n",
      "train metrics:\n",
      "  loss: 0.8620604937380932\n",
      "  accuracy: 71.99246452818525\n",
      "validation metrics:\n",
      "  loss: 0.7789146222414509\n",
      "  accuracy: 74.23387096774194\n",
      "\n",
      "EPOCH #44\n",
      "train metrics:\n",
      "  loss: 0.8571405201516253\n",
      "  accuracy: 71.75753543934924\n",
      "validation metrics:\n",
      "  loss: 0.8213571752271345\n",
      "  accuracy: 72.22782258064517\n",
      "\n",
      "EPOCH #45\n",
      "train metrics:\n",
      "  loss: 0.8366646034286377\n",
      "  accuracy: 72.69946806887363\n",
      "validation metrics:\n",
      "  loss: 0.7809630321158517\n",
      "  accuracy: 73.84072580645162\n",
      "\n",
      "EPOCH #46\n",
      "train metrics:\n",
      "  loss: 0.8368549305073758\n",
      "  accuracy: 72.849438509028\n",
      "validation metrics:\n",
      "  loss: 0.7675976676325644\n",
      "  accuracy: 75.50403225806451\n",
      "\n",
      "EPOCH #47\n",
      "train metrics:\n",
      "  loss: 0.8317623423135027\n",
      "  accuracy: 72.72975767419693\n",
      "validation metrics:\n",
      "  loss: 0.6868226321474198\n",
      "  accuracy: 77.87298387096774\n",
      "\n",
      "EPOCH #48\n",
      "train metrics:\n",
      "  loss: 0.8288256564038865\n",
      "  accuracy: 72.92036050025453\n",
      "validation metrics:\n",
      "  loss: 0.7220793337591233\n",
      "  accuracy: 76.09879032258064\n",
      "\n",
      "EPOCH #49\n",
      "train metrics:\n",
      "  loss: 0.8101932346820832\n",
      "  accuracy: 73.75591015105552\n",
      "validation metrics:\n",
      "  loss: 0.8908107968895966\n",
      "  accuracy: 72.11693548387096\n",
      "\n",
      "EPOCH #50\n",
      "train metrics:\n",
      "  loss: 0.796132983045375\n",
      "  accuracy: 74.23093971090114\n",
      "validation metrics:\n",
      "  loss: 0.7448960078820106\n",
      "  accuracy: 75.69556451612904\n",
      "\n",
      "EPOCH #51\n",
      "train metrics:\n",
      "  loss: 0.7676975657648228\n",
      "  accuracy: 74.89804963456824\n",
      "validation metrics:\n",
      "  loss: 0.6849139616374047\n",
      "  accuracy: 77.76209677419355\n",
      "\n",
      "EPOCH #52\n",
      "train metrics:\n",
      "  loss: 0.7774308441801274\n",
      "  accuracy: 75.05688531753864\n",
      "validation metrics:\n",
      "  loss: 0.6711000887857329\n",
      "  accuracy: 77.62096774193549\n",
      "\n",
      "EPOCH #53\n",
      "train metrics:\n",
      "  loss: 0.7720937766293262\n",
      "  accuracy: 74.99852244600336\n",
      "validation metrics:\n",
      "  loss: 0.7183105034092742\n",
      "  accuracy: 76.71370967741936\n",
      "\n",
      "EPOCH #54\n",
      "train metrics:\n",
      "  loss: 0.749338881259269\n",
      "  accuracy: 75.32284276434716\n",
      "validation metrics:\n",
      "  loss: 0.6707218633063378\n",
      "  accuracy: 78.72983870967742\n",
      "\n",
      "EPOCH #55\n",
      "train metrics:\n",
      "  loss: 0.7670710103308901\n",
      "  accuracy: 75.01255909534211\n",
      "validation metrics:\n",
      "  loss: 0.643966265443352\n",
      "  accuracy: 79.93951612903226\n",
      "\n",
      "EPOCH #56\n",
      "train metrics:\n",
      "  loss: 0.7458285267682786\n",
      "  accuracy: 75.60800826701713\n",
      "validation metrics:\n",
      "  loss: 0.6619872339670697\n",
      "  accuracy: 78.2258064516129\n",
      "\n",
      "EPOCH #57\n",
      "train metrics:\n",
      "  loss: 0.7338599784577147\n",
      "  accuracy: 76.26108154946185\n",
      "validation metrics:\n",
      "  loss: 0.6751904598467292\n",
      "  accuracy: 78.125\n",
      "\n",
      "EPOCH #58\n",
      "train metrics:\n",
      "  loss: 0.7115577599469651\n",
      "  accuracy: 76.75236404094291\n",
      "validation metrics:\n",
      "  loss: 0.7074834847402188\n",
      "  accuracy: 77.21774193548387\n",
      "\n",
      "EPOCH #59\n",
      "train metrics:\n",
      "  loss: 0.7127255182316963\n",
      "  accuracy: 76.78782504467254\n",
      "validation metrics:\n",
      "  loss: 0.6103873192182472\n",
      "  accuracy: 80.69556451612904\n",
      "\n",
      "EPOCH #60\n",
      "train metrics:\n",
      "  loss: 0.703628408274752\n",
      "  accuracy: 77.29905434466423\n",
      "validation metrics:\n",
      "  loss: 0.6325420625507832\n",
      "  accuracy: 78.78024193548387\n",
      "\n",
      "EPOCH #61\n",
      "train metrics:\n",
      "  loss: 0.7161993026099307\n",
      "  accuracy: 76.6770094526575\n",
      "validation metrics:\n",
      "  loss: 0.5967916291086904\n",
      "  accuracy: 81.19959677419355\n",
      "\n",
      "EPOCH #62\n",
      "train metrics:\n",
      "  loss: 0.7009880209856845\n",
      "  accuracy: 77.26654844892786\n",
      "validation metrics:\n",
      "  loss: 0.6075073235457943\n",
      "  accuracy: 79.88911290322581\n",
      "\n",
      "EPOCH #63\n",
      "train metrics:\n",
      "  loss: 0.6976306579214462\n",
      "  accuracy: 77.53546097126413\n",
      "validation metrics:\n",
      "  loss: 0.6358691563889864\n",
      "  accuracy: 79.03225806451613\n",
      "\n",
      "EPOCH #64\n",
      "train metrics:\n",
      "  loss: 0.6770623115465996\n",
      "  accuracy: 78.07845743057575\n",
      "validation metrics:\n",
      "  loss: 0.57291087490176\n",
      "  accuracy: 81.75403225806451\n",
      "\n",
      "EPOCH #65\n",
      "train metrics:\n",
      "  loss: 0.6791349707765783\n",
      "  accuracy: 77.80289595583652\n",
      "validation metrics:\n",
      "  loss: 0.5718133301744538\n",
      "  accuracy: 82.00604838709677\n",
      "\n",
      "EPOCH #66\n",
      "train metrics:\n",
      "  loss: 0.6604423902136214\n",
      "  accuracy: 78.38652480105137\n",
      "validation metrics:\n",
      "  loss: 0.6099834623896787\n",
      "  accuracy: 79.88911290322581\n",
      "\n",
      "EPOCH #67\n",
      "train metrics:\n",
      "  loss: 0.6552426102630635\n",
      "  accuracy: 78.43823875264918\n",
      "validation metrics:\n",
      "  loss: 0.5916106656434075\n",
      "  accuracy: 80.84677419354838\n",
      "\n",
      "EPOCH #68\n",
      "train metrics:\n",
      "  loss: 0.6535981477575099\n",
      "  accuracy: 78.95759454280773\n",
      "validation metrics:\n",
      "  loss: 0.5909434041128524\n",
      "  accuracy: 81.09879032258064\n",
      "\n",
      "EPOCH #69\n",
      "train metrics:\n",
      "  loss: 0.6421101698850064\n",
      "  accuracy: 78.80836287153528\n",
      "validation metrics:\n",
      "  loss: 0.5705779262728268\n",
      "  accuracy: 82.00604838709677\n",
      "\n",
      "EPOCH #70\n",
      "train metrics:\n",
      "  loss: 0.6385956384400104\n",
      "  accuracy: 79.17257680690035\n",
      "validation metrics:\n",
      "  loss: 0.5551581164942153\n",
      "  accuracy: 83.01411290322581\n",
      "\n",
      "EPOCH #71\n",
      "train metrics:\n",
      "  loss: 0.6383460388538685\n",
      "  accuracy: 79.21690306967878\n",
      "validation metrics:\n",
      "  loss: 0.5462668806975407\n",
      "  accuracy: 83.87096774193549\n",
      "\n",
      "EPOCH #72\n",
      "train metrics:\n",
      "  loss: 0.6135032317264283\n",
      "  accuracy: 79.99778367712143\n",
      "validation metrics:\n",
      "  loss: 0.5276875915005803\n",
      "  accuracy: 83.51814516129032\n",
      "\n",
      "EPOCH #73\n",
      "train metrics:\n",
      "  loss: 0.6084345125137491\n",
      "  accuracy: 80.05910164041723\n",
      "validation metrics:\n",
      "  loss: 0.5534735107493978\n",
      "  accuracy: 82.76209677419355\n",
      "\n",
      "EPOCH #74\n",
      "train metrics:\n",
      "  loss: 0.6239675954618352\n",
      "  accuracy: 79.59958625955784\n",
      "validation metrics:\n",
      "  loss: 0.5369483661507407\n",
      "  accuracy: 83.36693548387096\n",
      "\n",
      "EPOCH #75\n",
      "train metrics:\n",
      "  loss: 0.6111264150510443\n",
      "  accuracy: 79.66607563749272\n",
      "validation metrics:\n",
      "  loss: 0.5424486737578146\n",
      "  accuracy: 83.06451612903226\n",
      "\n",
      "EPOCH #76\n",
      "train metrics:\n",
      "  loss: 0.5910918099449036\n",
      "  accuracy: 80.89095743057575\n",
      "validation metrics:\n",
      "  loss: 0.5370408570574176\n",
      "  accuracy: 82.9133064516129\n",
      "\n",
      "EPOCH #77\n",
      "train metrics:\n",
      "  loss: 0.599311626433058\n",
      "  accuracy: 80.3354018840384\n",
      "validation metrics:\n",
      "  loss: 0.5395137321564459\n",
      "  accuracy: 83.46774193548387\n",
      "\n",
      "EPOCH #78\n",
      "train metrics:\n",
      "  loss: 0.5802050390142075\n",
      "  accuracy: 81.2581264739341\n",
      "validation metrics:\n",
      "  loss: 0.5680195721347006\n",
      "  accuracy: 81.30040322580645\n",
      "\n",
      "EPOCH #79\n",
      "train metrics:\n",
      "  loss: 0.5672874495704123\n",
      "  accuracy: 81.51078604840218\n",
      "validation metrics:\n",
      "  loss: 0.5471641902601526\n",
      "  accuracy: 82.5100806451613\n",
      "\n",
      "EPOCH #80\n",
      "train metrics:\n",
      "  loss: 0.582872943865492\n",
      "  accuracy: 80.73212173137259\n",
      "validation metrics:\n",
      "  loss: 0.5411392493894503\n",
      "  accuracy: 83.36693548387096\n",
      "\n",
      "EPOCH #81\n",
      "train metrics:\n",
      "  loss: 0.5492202304462169\n",
      "  accuracy: 81.97916665584484\n",
      "validation metrics:\n",
      "  loss: 0.4939203986657723\n",
      "  accuracy: 85.18145161290323\n",
      "\n",
      "EPOCH #82\n",
      "train metrics:\n",
      "  loss: 0.552793073083492\n",
      "  accuracy: 81.88091015105552\n",
      "validation metrics:\n",
      "  loss: 0.5251497675724808\n",
      "  accuracy: 84.32459677419355\n",
      "\n",
      "EPOCH #83\n",
      "train metrics:\n",
      "  loss: 0.5594432335584721\n",
      "  accuracy: 81.5846630989237\n",
      "validation metrics:\n",
      "  loss: 0.49607262228645627\n",
      "  accuracy: 84.57661290322581\n",
      "\n",
      "EPOCH #84\n",
      "train metrics:\n",
      "  loss: 0.5501720380592854\n",
      "  accuracy: 82.07668437551945\n",
      "validation metrics:\n",
      "  loss: 0.49988544367313864\n",
      "  accuracy: 84.82862903225806\n",
      "\n",
      "EPOCH #85\n",
      "train metrics:\n",
      "  loss: 0.5458316895080374\n",
      "  accuracy: 82.24881794706305\n",
      "validation metrics:\n",
      "  loss: 0.521878611867226\n",
      "  accuracy: 83.51814516129032\n",
      "\n",
      "EPOCH #86\n",
      "train metrics:\n",
      "  loss: 0.5582632948585013\n",
      "  accuracy: 82.10106381355448\n",
      "validation metrics:\n",
      "  loss: 0.48250776802700374\n",
      "  accuracy: 84.92943548387096\n",
      "\n",
      "EPOCH #87\n",
      "train metrics:\n",
      "  loss: 0.5436462838281977\n",
      "  accuracy: 82.11510045477685\n",
      "validation metrics:\n",
      "  loss: 0.48127362403958557\n",
      "  accuracy: 84.92943548387096\n",
      "\n",
      "EPOCH #88\n",
      "train metrics:\n",
      "  loss: 0.5321248953646802\n",
      "  accuracy: 82.65809689785571\n",
      "validation metrics:\n",
      "  loss: 0.48248615314162546\n",
      "  accuracy: 84.6774193548387\n",
      "\n",
      "EPOCH #89\n",
      "train metrics:\n",
      "  loss: 0.533540057692122\n",
      "  accuracy: 82.9646867468002\n",
      "validation metrics:\n",
      "  loss: 0.48448834904739935\n",
      "  accuracy: 84.57661290322581\n",
      "\n",
      "EPOCH #90\n",
      "train metrics:\n",
      "  loss: 0.5405323845908997\n",
      "  accuracy: 82.63223993828956\n",
      "validation metrics:\n",
      "  loss: 0.4901880598777244\n",
      "  accuracy: 84.0725806451613\n",
      "\n",
      "EPOCH #91\n",
      "train metrics:\n",
      "  loss: 0.5269659665987847\n",
      "  accuracy: 82.75413709599921\n",
      "validation metrics:\n",
      "  loss: 0.4807615662594476\n",
      "  accuracy: 84.32459677419355\n",
      "\n",
      "EPOCH #92\n",
      "train metrics:\n",
      "  loss: 0.5365222412220976\n",
      "  accuracy: 82.54063236967046\n",
      "validation metrics:\n",
      "  loss: 0.48635365364832744\n",
      "  accuracy: 84.42540322580645\n",
      "\n",
      "EPOCH #93\n",
      "train metrics:\n",
      "  loss: 0.5169477065192892\n",
      "  accuracy: 83.44932030211103\n",
      "validation metrics:\n",
      "  loss: 0.5041270099970843\n",
      "  accuracy: 84.72782258064517\n",
      "\n",
      "EPOCH #94\n",
      "train metrics:\n",
      "  loss: 0.5177853185128658\n",
      "  accuracy: 83.455969254514\n",
      "validation metrics:\n",
      "  loss: 0.5007327991432601\n",
      "  accuracy: 84.17338709677419\n",
      "\n",
      "EPOCH #95\n",
      "train metrics:\n",
      "  loss: 0.525853915893017\n",
      "  accuracy: 82.849438509028\n",
      "validation metrics:\n",
      "  loss: 0.4734301249000935\n",
      "  accuracy: 85.28225806451613\n",
      "\n",
      "EPOCH #96\n",
      "train metrics:\n",
      "  loss: 0.5133493227844542\n",
      "  accuracy: 83.50916072764295\n",
      "validation metrics:\n",
      "  loss: 0.47579522995698836\n",
      "  accuracy: 84.92943548387096\n",
      "\n",
      "EPOCH #97\n",
      "train metrics:\n",
      "  loss: 0.5336749194784367\n",
      "  accuracy: 82.6145094526575\n",
      "validation metrics:\n",
      "  loss: 0.48898766843992614\n",
      "  accuracy: 85.03024193548387\n",
      "\n",
      "EPOCH #98\n",
      "train metrics:\n",
      "  loss: 0.5234606716227024\n",
      "  accuracy: 82.9646867468002\n",
      "validation metrics:\n",
      "  loss: 0.48371772042986366\n",
      "  accuracy: 84.77822580645162\n",
      "\n",
      "EPOCH #99\n",
      "train metrics:\n",
      "  loss: 0.514968086113321\n",
      "  accuracy: 83.17966902712558\n",
      "validation metrics:\n",
      "  loss: 0.4812319797553843\n",
      "  accuracy: 84.52620967741936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "N_WARMUP_EPOCHS = 10\n",
    "\n",
    "train_loader = dataloaders['pretrain_train_dataloader']\n",
    "validation_loader = dataloaders['pretrain_validation_dataloader']\n",
    "\n",
    "# using `search_space.model_parameters()` as optimizable variables\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "# using `EnotPretrainOptimizer` as a default optimizer\n",
    "enot_optimizer = EnotPretrainOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "\n",
    "len_train_loader = len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train_loader*N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train_loader*N_WARMUP_EPOCHS)\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    search_space.train()\n",
    "    train_metrics_acc = {\n",
    "        'loss': 0.0,\n",
    "        'accuracy': 0.0,\n",
    "        'n': 0,\n",
    "    }\n",
    "    for inputs, labels in train_loader:\n",
    "        # By default, `EnotPretrainOptimizer` requires one batch of train data to initialize optimizations, \n",
    "        # so you should run `search_space.initialize_output_distribution_optimization(...)` before the first \n",
    "        # model step. You can disable optimization checking in `EnotPretrainOptimizer` constructor \n",
    "        # (`check_recommended_optimizations` parameter), but this is not recommended.\n",
    "        if not search_space.output_distribution_optimization_enabled:\n",
    "            search_space.initialize_output_distribution_optimization(inputs)\n",
    "\n",
    "        enot_optimizer.zero_grad()\n",
    "        # Wrapping model step and backward with closure.\n",
    "        # Alternatively, here is `enot_optimizer.model_step(...)` example usage for gradient accumulation:\n",
    "        #\n",
    "        # enot_optimizer.zero_grad()\n",
    "        # for inputs, labels in train_loader:\n",
    "        #\n",
    "        #     def closure():\n",
    "        #         ...\n",
    "        #\n",
    "        #     enot_optimizer.model_step(closure)\n",
    "        #     if (n + 1) % 10 == 0:\n",
    "        #         enot_optimizer.step()\n",
    "        #         enot_optimizer.zero_grad()\n",
    "        def closure():\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_loss.backward()\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            train_metrics_acc['loss'] += batch_loss.item()\n",
    "            train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "            train_metrics_acc['n'] += 1\n",
    "\n",
    "        enot_optimizer.step(closure)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "    train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "\n",
    "    search_space.eval()\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    for inputs, labels in validation_loader:\n",
    "\n",
    "        # Sample random architecture from the search space to estimate\n",
    "        # search space expected metrics.\n",
    "        search_space.sample_random_arch()\n",
    "\n",
    "        pred_labels = search_space(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "        validation_loss += batch_loss.item()\n",
    "        validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCH #99\n",
    "# train metrics:\n",
    "#   loss: 0.514968086113321\n",
    "#   accuracy: 83.17966902712558\n",
    "# validation metrics:\n",
    "#   loss: 0.4812319797553843\n",
    "#   accuracy: 84.52620967741936\n",
    "    \n",
    "torch.save({'model': search_space.state_dict()}, PROJECT_DIR / 'common_init_result.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
